
@article{taghibakhshi_learning_nodate,
	title = {Learning {Interface} {Conditions} in {Domain} {Decomposition} {Solvers}},
	copyright = {All rights reserved},
	abstract = {Domain decomposition methods are widely used and effective in the approximation of solutions to partial differential equations. Yet the optimal construction of these methods requires tedious analysis and is often available only in simpliﬁed, structured-grid settings, limiting their use for more complex problems. In this work, we generalize optimized Schwarz domain decomposition methods to unstructured-grid problems, using Graph Convolutional Neural Networks (GCNNs) and unsupervised learning to learn optimal modiﬁcations at subdomain interfaces. A key ingredient in our approach is an improved loss function, enabling effective training on relatively small problems, but robust performance on arbitrarily large problems, with computational cost linear in problem size. The performance of the learned linear solvers is compared with both classical and optimized domain decomposition algorithms, for both structured- and unstructured-grid problems.},
	language = {en},
	author = {Taghibakhshi, Ali and Zaman, Tareq and Olson, Luke and Nytko, Nicolas and MacLachlan, Scott},
	file = {Taghibakhshi et al. - Learning Interface Conditions in Domain Decomposit.pdf:files/11/Taghibakhshi et al. - Learning Interface Conditions in Domain Decomposit.pdf:application/pdf},
}
